---
title: "exploratory_data_analysis"
author: "Corwin Dark"
date: "2024-05-10"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```



```{r}

# Old data file
#dataIn <- read.delim("data/NABR_ClimExposure", sep =  " ")



# load data in
setwd("~/dsan/spring2024/arches_climate")
dataIn <- read.csv("data/NABR_historic.csv")
hist_dat <- read.csv('data/hist_data.csv')

dataIn <- dataIn[rowSums(is.na(dataIn)) != ncol(dataIn), ]
dataIn <- dataIn[!duplicated(dataIn),]


# annual collumns incorrect and need to be recalculated

```

```{r}

annuals <- c("T_Annual", "PPT_Annual")
dataIn <- select(dataIn, -c("T_Annual", "PPT_Annual"))


```

```{r}

# create lookup table for locations
uq_location <- paste(hist_dat$long, hist_dat$lat)
uq_loc_table <- data.frame(id = uq_location, long = hist_dat$long, lat = hist_dat$lat)

uq_loc_table <- uq_loc_table[!duplicated(uq_loc_table$id),]

write.csv(uq_loc_table, "location_table.csv")

ggplot()

```


```{r}

uqID <- paste(dataIn$long, dataIn$lat, dataIn$year, dataIn$scenario)


```


```{r}

dataIn$uqID <- uqID
```

```{r}

uqIDs <- unique(uqID)
# create new copy of dataframe that we will combine rows into
cleanData <- dataIn[1,]

#nrow(uqID)
for(i in 1:length(uqIDs)) {
  
  if(i %% 1000 == 0){
    print(i)
  }
  iter_id <- uqIDs[i]
  iter_data <- dataIn %>% filter(uqID == iter_id)

  
    for(j in 1:ncol(iter_data)) {
      
      iter_col = unique(iter_data[,j])
      
      
      # if all entries, NA, record NA
      if(sum(is.na(iter_col)) == length(iter_col)) {
        cleanData[i,j] = NA 
        
        
      # if only one non-NA entry, record that  
      } else if(sum(!is.na(iter_col)) == 1){
        cleanData[i,j] = iter_col[!is.na(iter_col)]
      
      # if entries all the same, record that
      } else if(length(unique(iter_col)) == 1) {
        cleanData[i,j] = iter_col[1]
      
      # if entries conflict, print error
      } else if(length(unique(iter_col)) > 1 ) {
        
        print(paste("error, i: ", str(i), " j: ", str(j)))
        
        print(unique(iter_col))
        print(is.na(iter_col))
        
        cleanData[i,j] = NA
      
      }
    
  }
    
}


```


```{r}
library(sf)
#library(mapview)
library(ggmap)

register_stadiamaps("1f3f7fe5-9ce7-4a0e-ad81-66cd97d29ee2", write = TRUE)

#mapview(dataIn, xcol = "long", ycol = "lat", crs = 4269, grid = FALSE)
xmin = -120
xmax = -90
ymin = 30
ymax = 40

bbox <- make_bbox(long, lat, data = hist_dat)


map <- get_stadiamap(bbox = bbox, maptype = "outdoors", zoom = 16 )

ggmap(map) + geom_point(data = hist_dat, aes(x = long, y = lat))

ggplot(hist_dat, aes(x = long, y = lat)) + geom_blank() + coord_map('mercator') + annotation_raster(ggmap, xmin, xmax, ymin, ymax)

```

```{r}

# slight upward trend
ggplot(data = hist_dat, aes(x = year, y = ExtremeShortTermDryStress_Summer_whole)) + geom_point()

# Severe downward trend
ggplot(data = hist_dat, aes(x = year, y = FrostDays_Winter)) + geom_point()


# Soil water availabikity drops greatly
ggplot(data = hist_dat, aes(x = year, y = NonDrySWA_Summer_whole)) + geom_point()


ggplot(data = hist_dat, aes(x = year, y = PPT_Winter)) + geom_point()


# not much of a trend       
ggplot(data = hist_dat, aes(x = year, y = PPT_Summer, color = treecanopy)) + geom_point()

# slight increase in avg?
ggplot(data = hist_dat, aes(x = year, y = DrySoilDays_Summer_whole, color = treecanopy)) + geom_point()

#  Dramatic uptick
ggplot(data = hist_dat, aes(x = year, y = T_Summer, color = treecanopy)) + geom_point()

# Dramatic downtick in recent years
ggplot(data = hist_dat, aes(x = year, y = VWC_Winter_whole, color = treecanopy)) + geom_point()

# not much discernable, avg might be dropping slightly though
ggplot(data = hist_dat, aes(x = year, y = VWC_Summer_whole, color = treecanopy)) + geom_point()

# Not clear trend
ggplot(data = hist_dat, aes(x = year, y = VWC_Fall_whole, color = treecanopy)) + geom_point()


```

```{r}


# now let's try with avg curve of VWC
vwc_avg <- hist_dat %>%
  group_by(year) %>%
  summarise(winter_avg = mean(VWC_Winter_whole), spring_avg = mean(VWC_Spring_whole), summer_avg = mean(VWC_Summer_whole), fall_avg = mean(VWC_Fall_whole))


vwc_avg = pivot_longer(vwc_avg, cols = 'winter_avg':'fall_avg', names_to = 'season', values_to = 'VWC')


ggplot(data = vwc_avg, aes(x = season, y = VWC, color = year)) + geom_line()
```


```{r}

library(corrplot)
library(GGally)

# filter only numeric data from history dataframe
num_hist_dat = hist_dat[,c(2,3,4,8:28)]

cdat = cor(num_hist_dat)



```


```{r}

write.csv(cleanData, "hist_data.csv")

```

```{r}

write.csv(dataIn, "rawdata.csv")

```


```{r}

hist_dat$shrubland <- hist_dat$Ann_Herb + hist_dat$Herb + hist_dat$Shrub + hist_dat$Litter
hist_dat$uq_loc <- uq_location

hist_dat$drydays <- hist_dat$DrySoilDays_Summer_whole > 0

tempDF <- hist_dat %>%
  filter(year == 1980)

temp2018 <- hist_dat %>%
  filter(year == 2018 )

sum(as.numeric(temp2018$drydays))
sum(as.numeric(tempDF$drydays))

uq_loc_table$shrubland <- tempDF$shrubland
uq_loc_table$treecover <- tempDF$treecanopy
uq_loc_table$barren <- tempDF$Bare
uq_loc_table$dry2018 <- temp2018$DrySoilDays_Summer_whole
uq_loc_table$dry1980 <- tempDF$DrySoilDays_Summer_whole
uq_loc_table$frost2018 <- temp2018$FrostDays_Winter
uq_loc_table$frost1980 <- tempDF$FrostDays_Winter
uq_loc_table$summerT2018 <- temp2018$T_Summer
uq_loc_table$summerT1980 <- tempDF$T_Summer


write.csv(uq_loc_table, 'vizdatasave.csv')
```